# deep-learning-v2-pytorch
 Udacity's Deep Learning v7 Nanodegree program
 
# Table Of Contents
# Tutorials
#Introduction to Neural Networks
Introduction to Neural Networks: Learn how to implement gradient descent and apply it to predicting patterns in student admissions data.
Sentiment Analysis with NumPy: Andrew Trask leads you through building a sentiment analysis model, predicting if some text is positive or negative.
Introduction to PyTorch: Learn how to build neural networks in PyTorch and use pre-trained networks for state-of-the-art image classifiers.

# Convolutional Neural Networks
Convolutional Neural Networks: Visualize the output of layers that make up a CNN. Learn how to define and train a CNN for classifying MNIST data, a handwritten digit database that is notorious in the fields of machine and deep learning. Also, define and train a CNN for classifying images in the CIFAR10 dataset.
Transfer Learning. In practice, most people don't train their own networks on huge datasets; they use pre-trained networks such as VGGnet. Here you'll use VGGnet to help classify images of flowers without training an end-to-end network from scratch.
Weight Initialization: Explore how initializing network weights affects performance.
Autoencoders: Build models for image compression and de-noising, using feedforward and convolutional networks in PyTorch.
Style Transfer: Extract style and content features from images, using a pre-trained network. Implement style transfer according to the paper, Image Style Transfer Using Convolutional Neural Networks by Gatys et. al. Define appropriate losses for iteratively creating a target, style-transferred image of your own design!

# Recurrent Neural Networks
Intro to Recurrent Networks (Time series & Character-level RNN): Recurrent neural networks are able to use information about the sequence of data, such as the sequence of characters in text; learn how to implement these in PyTorch for a variety of tasks.
Embeddings (Word2Vec): Implement the Word2Vec model to find semantic representations of words for use in natural language processing.
Sentiment Analysis RNN: Implement a recurrent neural network that can predict if the text of a moview review is positive or negative.
Attention: Implement attention and apply it to annotation vectors.

# Generative Adversarial Networks
Generative Adversarial Network on MNIST: Train a simple generative adversarial network on the MNIST dataset.
Batch Normalization: Learn how to improve training rates and network stability with batch normalizations.
Deep Convolutional GAN (DCGAN): Implement a DCGAN to generate new images based on the Street View House Numbers (SVHN) dataset.
CycleGAN: Implement a CycleGAN that is designed to learn from unpaired and unlabeled data; use trained generators to transform images from summer to winter and vice versa.
Deploying a Model (with AWS SageMaker)
All exercise and project notebooks for the lessons on model deployment can be found in the linked, Github repo. Learn to deploy pre-trained models using AWS SageMaker.

# Projects
Predicting Bike-Sharing Patterns: Implement a neural network in NumPy to predict bike rentals.
Dog Breed Classifier: Build a convolutional neural network with PyTorch to classify any image (even an image of a face) as a specific dog breed.
TV Script Generation: Train a recurrent neural network to generate scripts in the style of dialogue from Seinfeld.
Face Generation: Use a DCGAN on the CelebA dataset to generate images of new and realistic human faces.
